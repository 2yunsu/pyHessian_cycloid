{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Zhewei Yao <https://github.com/yaozhewei>, Amir Gholami <http://amirgholami.org/>\n",
    "\n",
    "\n",
    "This tutorial shows how to compute the Hessian information using (randomized) numerical linear algebra for both explicit Hessian (the matrix is given) as well as implicit Hessian (the matrix is ungiven).\n",
    "\n",
    "We'll start by doing the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import copy\n",
    "from torchvision import datasets, transforms\n",
    "from utils import * # get the dataset\n",
    "from pyhessian import hessian # Hessian computation\n",
    "from density_plot import get_esd_plot # ESD plot\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable cuda devices\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following part shows how to use power iteration to get the top eigenvalue of a matrix without explicitly having access to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We first show an example with Numpy for a random matrix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # the matrix size\n",
    "\n",
    "# generate the matrix\n",
    "A = np.random.randn(n, n)\n",
    "B = A @ A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use numpy to compute the ground truth eigenvalues. We will then check the results with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top eigenvalue of B is 23.9784\n"
     ]
    }
   ],
   "source": [
    "# use np.eigs to get the top eigenvalue of B\n",
    "eigs, _ = np.linalg.eig(B)\n",
    "\n",
    "print(\"The top eigenvalue of B is %.4f\"%np.sort(eigs)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to comptue the top eigenvalue of B without explicitly using. To do so, we will use a method called Power Iteration:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Power_iteration\n",
    "\n",
    "The algorithm is very simple and efficiet to compute the top eigenvalue:\n",
    "$$v_{i+1} = \\frac{Bv_i}{\\|Bv_i\\|}.$$\n",
    "\n",
    "As such, we only need to have access to the *application* of B to a given vector $v_i$ and not the matrix B itself. This application is commonly referred to as *matvec* in literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1 current estimated top eigvalue: 16.6602\n",
      "Step  2 current estimated top eigvalue: 22.1014\n",
      "Step  3 current estimated top eigvalue: 23.3392\n",
      "Step  4 current estimated top eigvalue: 23.7363\n",
      "Step  5 current estimated top eigvalue: 23.8803\n",
      "Step  6 current estimated top eigvalue: 23.9371\n",
      "Step  7 current estimated top eigvalue: 23.9607\n",
      "Step  8 current estimated top eigvalue: 23.9707\n",
      "Step  9 current estimated top eigvalue: 23.9751\n",
      "Step 10 current estimated top eigvalue: 23.9769\n",
      "Step 11 current estimated top eigvalue: 23.9778\n",
      "Step 12 current estimated top eigvalue: 23.9781\n",
      "Step 13 current estimated top eigvalue: 23.9783\n",
      "Step 14 current estimated top eigvalue: 23.9784\n",
      "Step 15 current estimated top eigvalue: 23.9784\n",
      "Step 16 current estimated top eigvalue: 23.9784\n",
      "Step 17 current estimated top eigvalue: 23.9784\n",
      "Step 18 current estimated top eigvalue: 23.9784\n",
      "Step 19 current estimated top eigvalue: 23.9784\n",
      "Step 20 current estimated top eigvalue: 23.9784\n",
      "Step 21 current estimated top eigvalue: 23.9784\n",
      "Step 22 current estimated top eigvalue: 23.9784\n",
      "Step 23 current estimated top eigvalue: 23.9784\n",
      "Step 24 current estimated top eigvalue: 23.9784\n",
      "Step 25 current estimated top eigvalue: 23.9784\n",
      "Step 26 current estimated top eigvalue: 23.9784\n",
      "Step 27 current estimated top eigvalue: 23.9784\n",
      "Step 28 current estimated top eigvalue: 23.9784\n",
      "Step 29 current estimated top eigvalue: 23.9784\n",
      "Step 30 current estimated top eigvalue: 23.9784\n",
      "Step 31 current estimated top eigvalue: 23.9784\n",
      "Step 32 current estimated top eigvalue: 23.9784\n",
      "Step 33 current estimated top eigvalue: 23.9784\n",
      "Step 34 current estimated top eigvalue: 23.9784\n",
      "Step 35 current estimated top eigvalue: 23.9784\n",
      "Step 36 current estimated top eigvalue: 23.9784\n",
      "Step 37 current estimated top eigvalue: 23.9784\n",
      "Step 38 current estimated top eigvalue: 23.9784\n",
      "Step 39 current estimated top eigvalue: 23.9784\n",
      "Step 40 current estimated top eigvalue: 23.9784\n"
     ]
    }
   ],
   "source": [
    "# use power iteration to get the top eigenvalue of B\n",
    "v = np.random.randn(n, 1)\n",
    "\n",
    "for i in range(40):\n",
    "    v = v / np.linalg.norm(v)\n",
    "    print(\"Step %2d current estimated top eigvalue: %.4f\"%(i+1,v.T @ B @ v))\n",
    "    v = B @ v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the result of the power iteration and the one we got from numpy match very well.\n",
    "\n",
    "We can apply the same techinique for neural networks as well, and in particular to Hessian!\n",
    "\n",
    "Importantly there has been a lot of misconception that we can not use Hessian for real world applications since\n",
    "we need to form it. Next you will see that this is not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use power iteration for NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "# change the model to eval mode to disable running stats upate\n",
    "model.eval()\n",
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData()\n",
    "\n",
    "# for illustrate, we only use one batch to do the tutorial\n",
    "for inputs, targets in train_loader:\n",
    "    break\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "model = model.cuda()\n",
    "inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hessian computation module\n",
    "hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(f'The top eigenvalue of this model is: {top_eigenvalues}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(top_n=2)\n",
    "print(f'The top two eigenvalues of this model are: {top_eigenvalues}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Hessian eigenvectors/eigenvalues to analyze the flat/sharpness of the loss landscape of your model, and plot the loss landscape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top eigenvector\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple function, that will allow us to perturb the model paramters and get the result\n",
    "def get_params(model_orig,  model_perb, direction, alpha):\n",
    "    for m_orig, m_perb, d in zip(model_orig.parameters(), model_perb.parameters(), direction):\n",
    "        m_perb.data = m_orig.data + alpha * d\n",
    "    return model_perb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda is a small scalar that we use to perturb the model parameters along the eigenvectors \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "for lam in lams:\n",
    "    model_perb = get_params(model, model_perb, top_eigenvector[0], lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhessian.utils import normalization\n",
    "\n",
    "# generate random vector to do the loss plot\n",
    "\n",
    "v = [torch.randn_like(p) for p in model.parameters()]\n",
    "v = normalization(v)\n",
    "\n",
    "\n",
    "# used to perturb your model \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "for lam in lams: \n",
    "    model_perb = get_params(model, model_perb, v, lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhessian.utils import normalization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# used to perturb your model \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "# generate gradient vector to do the loss plot\n",
    "loss = criterion(model_perb(inputs), targets)\n",
    "loss.backward()\n",
    "\n",
    "v = [p.grad.data for p in model_perb.parameters()]\n",
    "v = normalization(v)\n",
    "model_perb.zero_grad()\n",
    "\n",
    "\n",
    "for lam in lams: \n",
    "    model_perb = get_params(model, model_perb, v, lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following part shows how to use power iteration to get the trace/diagonal of the Hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We first show an example with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # the matrix size\n",
    "\n",
    "# generate the matrix\n",
    "A = np.random.randn(n, n)\n",
    "B = A @ A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct get the trace \n",
    "print(f'The trace of B is: {np.matrix.trace(B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hutchinson Method\n",
    "The algorithm is also very simple as power iteration: \n",
    "$$Tr(B) = \\mathbb{E}[v^TBv],$$\n",
    "$$Diag(B) = \\mathbb{E}[v \\bigodot Bv].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Hutchinson method to get the trace of B\n",
    "trace_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    v = np.random.randint(2, size=n)\n",
    "    v = v.reshape(n, 1) * 2 - 1\n",
    "    trace_list.append(v.T @ B @ v)\n",
    "    print(f'Step {i+1}, Current estimated trace: {np.mean(trace_list)}, \\\n",
    "          the current relative error: { (np.mean(trace_list) - np.matrix.trace(B)) / np.matrix.trace(B)} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Hutchinson method to get the diag of B\n",
    "diag_est = np.zeros([n, 1])\n",
    "\n",
    "for i in range(20):\n",
    "    v = np.random.randint(2, size=n)\n",
    "    v = v.reshape(n, 1) * 2 - 1\n",
    "    diag_est += np.multiply(v, (B @ v))\n",
    "    print(f'Step {i+1}, the current average relative error: { np.mean(np.abs(diag_est.reshape(-1) / (i+1) - np.diag(B)) / np.diag(B))} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Hutchison Method for NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "# change the model to eval mode to disable running stats upate\n",
    "model.eval()\n",
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData()\n",
    "\n",
    "# for illustrate, we only use one batch to do the tutorial\n",
    "for inputs, targets in train_loader:\n",
    "    break\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "model = model.cuda()\n",
    "inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hessian computation module\n",
    "hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = hessian_comp.trace()\n",
    "print(f'The trace of this model is: {np.mean(trace)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following section shows a more advantage example using stochastic lanczos algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_eigen, density_weight = hessian_comp.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_esd_plot(density_eigen, density_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
